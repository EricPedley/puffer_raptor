[base]
package = ocean
env_name = puffer_drone
policy_name = Drone
rnn_name = Recurrent

[policy]
linear_size = 64
lstm_size = 16

[rnn]
input_size = 16
hidden_size = 16

[vec]
num_envs = 8

[env]
task = HOVER
num_envs = 16
num_drones = 64
max_rings = 10
alpha_dist = 1.6395058017134763
alpha_omega = 0.0030754182107602924
alpha_vel = 0.0030754182107602924

hover_target_dist = 0.5
hover_dist = 0.05
hover_omega = 0.05
hover_vel = 0.01

[train]
total_timesteps = 200_000_000
adam_beta1 = 0.9685641381002181
adam_beta2 = 0.9998669904675317
adam_eps = 2.126717879849162e-12
anneal_lr = True
batch_size = auto
bptt_horizon = 64
checkpoint_interval = 200
clip_coef = 0.18012873753586928
ent_coef = 0.000387648149807597
gae_lambda = 0.9293358168827169
gamma = 0.984141993841902
learning_rate = 0.008243475513811082
max_grad_norm = 1.2572646778975056
max_minibatch_size = 32768
min_lr_ratio = 0.04167118625458488
minibatch_size = 8192
optimizer = muon
prio_alpha = 0.9020466761715137
prio_beta0 = 0.8752475564516432
update_epochs = 1
use_rnn = True
vf_clip_coef = 0.4339065498027027
vf_coef = 2.862480145508439
vtrace_c_clip = 1.784103163098018
vtrace_rho_clip = 1.4215568048769138

[sweep.env.alpha_dist]
distribution = log_normal
min = 0.001
max = 10.0
mean = 0.95
scale = auto

[sweep.env.alpha_omega]
distribution = log_normal
min = 0.000001
max = 10.0
mean = 0.001
scale = auto

[sweep.env.alpha_vel]
distribution = log_normal
min = 0.000001
max = 10.0
mean = 0.001
scale = auto

#[sweep.env.hover_dist]
#distribution = log_normal
#min = 0.001
#max = 1.0
#mean = 0.1
#scale = auto

#[sweep.env.hover_omega]
#distribution = log_normal
#min = 0.001
#max = 1.0
#mean = 0.1
#scale = auto

#[sweep.env.hover_vel]
#distribution = log_normal
#min = 0.001
#max = 1.0
#mean = 0.1
#scale = auto

#[sweep.env.dist_scale_1]
#distribution = log_normal
#min = 0.01
#max = 100.0
#mean = 1
#scale = auto

#[sweep.env.dist_scale_2]
#distribution = log_normal
#min = 0.01
#max = 100.0
#mean = 1
#scale = auto